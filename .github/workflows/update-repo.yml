name: Update APT Repository

on:
  repository_dispatch:
    types: [package-updated]  # This listens for the event from package repos
  workflow_dispatch:          # Manual trigger
  schedule:
    - cron: '0 6 * * *'        # Daily rebuild

jobs:
  update-apt-repo:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Debug repository dispatch
      if: github.event_name == 'repository_dispatch'
      run: |
        echo "Event type: ${{ github.event.action }}"
        echo "Client payload: ${{ toJson(github.event.client_payload) }}"
        echo "Triggered by: ${{ github.event.client_payload.repository }}"

    - name: Parse payload and determine target distribution
      id: payload
      run: |
        # Define supported distributions (single source of truth)
        ALL_DISTRIBUTIONS="stable unstable bookworm-stable bookworm-unstable trixie-stable trixie-unstable"
        echo "all_distributions=$ALL_DISTRIBUTIONS" >> $GITHUB_OUTPUT

        # Extract payload fields (defaults for backward compatibility and scheduled runs)
        DISTRO="${{ github.event.client_payload.distro }}"
        CHANNEL="${{ github.event.client_payload.channel }}"
        COMPONENT="${{ github.event.client_payload.component }}"
        TARGET_REPO="${{ github.event.client_payload.repository }}"

        # Set defaults if not provided
        DISTRO="${DISTRO:-any}"
        CHANNEL="${CHANNEL:-stable}"
        COMPONENT="${COMPONENT:-main}"

        # Normalize to lowercase for case-insensitive comparison
        DISTRO=$(echo "$DISTRO" | tr '[:upper:]' '[:lower:]')
        CHANNEL=$(echo "$CHANNEL" | tr '[:upper:]' '[:lower:]')
        COMPONENT=$(echo "$COMPONENT" | tr '[:upper:]' '[:lower:]')

        # Map to distribution name
        if [ "$DISTRO" = "any" ]; then
          DISTRIBUTION="$CHANNEL"
        else
          DISTRIBUTION="${DISTRO}-${CHANNEL}"
        fi

        echo "=== Payload Configuration ==="
        echo "Distro: $DISTRO"
        echo "Channel: $CHANNEL"
        echo "Component: $COMPONENT"
        echo "Distribution: $DISTRIBUTION"
        echo "Target Repository: ${TARGET_REPO:-<all repositories>}"

        # Export for later steps
        echo "distro=$DISTRO" >> $GITHUB_OUTPUT
        echo "channel=$CHANNEL" >> $GITHUB_OUTPUT
        echo "component=$COMPONENT" >> $GITHUB_OUTPUT
        echo "distribution=$DISTRIBUTION" >> $GITHUB_OUTPUT
        echo "target_repo=$TARGET_REPO" >> $GITHUB_OUTPUT

        # Determine if this is a targeted update or full rebuild
        if [ -n "$TARGET_REPO" ]; then
          echo "mode=targeted" >> $GITHUB_OUTPUT
          echo "Mode: Targeted update for $TARGET_REPO"
        else
          echo "mode=full" >> $GITHUB_OUTPUT
          echo "Mode: Full repository rebuild"
        fi

    - name: Discover package repositories
      id: discover
      run: |
        echo "Discovering repositories with 'apt-package' topic..."

        # Use GitHub API to find repos with apt-package topic
        repos=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
          "https://api.github.com/search/repositories?q=org:hatlabs+topic:apt-package" | \
          jq -r '.items[].full_name')

        echo "Found repositories:"
        echo "$repos"

        # Store for next step
        echo "repos<<EOF" >> $GITHUB_OUTPUT
        echo "$repos" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

    - name: Fetch existing repository (targeted mode)
      if: steps.payload.outputs.mode == 'targeted'
      run: |
        echo "=== Fetching existing repository from gh-pages ==="

        # Fetch gh-pages branch
        git fetch origin gh-pages --depth=1

        # Create apt-repo directory
        mkdir -p apt-repo

        # Extract existing repository content from gh-pages to apt-repo/
        # The gh-pages branch contains the published apt repository at root level
        git checkout origin/gh-pages -- pool dists hat-labs-apt-key.asc hat-labs-apt-key.gpg index.html 2>/dev/null || echo "No existing repository content"

        # Move fetched content into apt-repo directory
        if [ -d "pool" ]; then
          mv pool apt-repo/ 2>/dev/null || true
        fi
        if [ -d "dists" ]; then
          mv dists apt-repo/ 2>/dev/null || true
        fi
        if [ -f "hat-labs-apt-key.asc" ]; then
          mv hat-labs-apt-key.asc apt-repo/ 2>/dev/null || true
        fi
        if [ -f "hat-labs-apt-key.gpg" ]; then
          mv hat-labs-apt-key.gpg apt-repo/ 2>/dev/null || true
        fi
        if [ -f "index.html" ]; then
          mv index.html apt-repo/ 2>/dev/null || true
        fi

        echo "✓ Existing repository content preserved"
        echo "Pool contents:"
        ls -la apt-repo/pool/ 2>/dev/null || echo "  (empty)"
        echo "Distributions:"
        ls -la apt-repo/dists/ 2>/dev/null || echo "  (empty)"

    - name: Setup build environment
      run: |
        sudo apt-get update
        sudo apt-get install -y dpkg-dev apt-utils curl jq gnupg

        # Create packages directory
        mkdir -p packages

        MODE="${{ steps.payload.outputs.mode }}"

        if [ "$MODE" = "full" ]; then
          echo "=== Full rebuild mode: Creating fresh directory structure ==="
          # Create distribution-specific pool and distribution directories
          for dist in ${{ steps.payload.outputs.all_distributions }}; do
            echo "Creating distribution: $dist"
            mkdir -p "apt-repo/pool/$dist/main"
            mkdir -p "apt-repo/dists/$dist/main/binary-arm64"
            mkdir -p "apt-repo/dists/$dist/main/binary-armhf"
            mkdir -p "apt-repo/dists/$dist/main/binary-all"
          done
        else
          echo "=== Targeted mode: Preserving existing structure, creating missing directories ==="
          # In targeted mode, create apt-repo if it doesn't exist
          # but preserve existing content
          TARGET_DIST="${{ steps.payload.outputs.distribution }}"
          COMPONENT="${{ steps.payload.outputs.component }}"

          # Ensure target distribution directories exist (won't overwrite existing)
          mkdir -p "apt-repo/pool/$TARGET_DIST/$COMPONENT"
          mkdir -p "apt-repo/dists/$TARGET_DIST/$COMPONENT/binary-arm64"
          mkdir -p "apt-repo/dists/$TARGET_DIST/$COMPONENT/binary-armhf"
          mkdir -p "apt-repo/dists/$TARGET_DIST/$COMPONENT/binary-all"

          echo "✓ Ensured $TARGET_DIST/$COMPONENT directories exist"
        fi

        echo "=== Distribution directories ==="
        ls -la apt-repo/dists/ 2>/dev/null || echo "apt-repo/dists/ not yet created"

    - name: Import GPG signing key
      run: |
        echo "${{ secrets.APT_SIGNING_KEY }}" | gpg --import --batch
        # Get the key ID for signing
        GPG_KEY_ID=$(gpg --list-secret-keys --keyid-format LONG | grep sec | head -1 | sed 's/.*\/\([A-Z0-9]*\) .*/\1/')
        echo "GPG_KEY_ID=$GPG_KEY_ID" >> $GITHUB_ENV
        echo "Using GPG key: $GPG_KEY_ID"

    - name: Download packages
      run: |
        MODE="${{ steps.payload.outputs.mode }}"
        TARGET_REPO="${{ steps.payload.outputs.target_repo }}"
        CHANNEL="${{ steps.payload.outputs.channel }}"

        # Source helper functions (fail fast if missing)
        source scripts/suffix-parsing-functions.sh || { echo "❌ Failed to load suffix parsing functions"; exit 1; }
        source scripts/routing-functions.sh || { echo "❌ Failed to load routing functions"; exit 1; }

        # Function to download packages from a repository
        download_from_repo() {
          local repo=$1
          local release_tag=$2

          echo "=== Processing $repo (release: $release_tag) ==="

          # Get release info
          if [ "$release_tag" = "latest" ]; then
            echo "Fetching latest release from $repo..."
            release_info=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/$repo/releases/latest")
          elif [ "$release_tag" = "prerelease" ]; then
            echo "Fetching latest pre-release from $repo..."
            release_info=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/$repo/releases" | \
              jq '[.[] | select(.prerelease == true)] | .[0]')
          else
            echo "Fetching release $release_tag from $repo..."
            release_info=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/$repo/releases/tags/$release_tag")
          fi

          # Check if release exists
          if [ "$(echo "$release_info" | jq -r '.message // empty')" = "Not Found" ]; then
            echo "No release found for $repo (tag: $release_tag)"
            return
          fi

          # Check for null/empty release_info (e.g., when no pre-releases exist)
          if [ -z "$release_info" ] || [ "$release_info" = "null" ]; then
            if [ "$release_tag" = "prerelease" ]; then
              echo "No pre-release found for $repo"
            else
              echo "No release information found for $repo"
            fi
            return
          fi

          local actual_tag=$(echo "$release_info" | jq -r '.tag_name')
          echo "Release tag: $actual_tag"

          # Download all .deb files from the release
          echo "Downloading .deb files..."
          echo "$release_info" | jq -r '.assets[] | select(.name | endswith(".deb")) | "\(.name)|\(.browser_download_url)"' | \
          while IFS='|' read -r name url; do
            if [ -n "$name" ] && [ -n "$url" ]; then
              echo "Downloading $name..."
              temp_file="packages/temp_$name"
              curl -L --fail -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                   -H "Accept: application/octet-stream" \
                   "$url" -o "$temp_file"

              if [ $? -eq 0 ]; then
                echo "✓ Downloaded $name"

                # Extract package metadata (using || true to prevent script exit on missing fields)
                actual_version=$(dpkg-deb --field "$temp_file" Version 2>/dev/null || true)
                package_name=$(dpkg-deb --field "$temp_file" Package 2>/dev/null || true)
                architecture=$(dpkg-deb --field "$temp_file" Architecture 2>/dev/null || true)

                if [ -n "$actual_version" ] && [ -n "$package_name" ] && [ -n "$architecture" ]; then
                  # Parse suffix from original filename (|| true because return code 1 means no suffix found, not an error)
                  parse_package_suffix "$name" pkg_distro pkg_component || true
                  if [ $? -eq 0 ]; then
                    echo "  ✓ Parsed suffix: distro=$pkg_distro, component=$pkg_component"
                    # Validate parsed values
                    if ! validate_suffix "$pkg_distro" "$pkg_component"; then
                      echo "  ⚠️  Using fallback: distro=any, component=main"
                      pkg_distro="any"
                      pkg_component="main"
                    fi
                  else
                    echo "  No suffix found, using defaults: distro=$pkg_distro, component=$pkg_component"
                  fi

                  # Create canonical filename
                  correct_filename="${package_name}_${actual_version}_${architecture}.deb"
                  final_path="packages/$correct_filename"

                  mv "$temp_file" "$final_path"

                  # Store metadata for routing (used by later issues #30, #32)
                  {
                    echo "package=$package_name"
                    echo "version=$actual_version"
                    echo "architecture=$architecture"
                    echo "distro=$pkg_distro"
                    echo "component=$pkg_component"
                    echo "original_filename=$name"
                  } > "${final_path}.meta"

                  echo "  Package: $package_name"
                  echo "  Version: $actual_version"
                  echo "  Architecture: $architecture"
                  echo "  Distro: $pkg_distro"
                  echo "  Component: $pkg_component"
                  echo "  Filename: $correct_filename"
                else
                  echo "  ⚠️  Could not extract package metadata, keeping original filename"
                  mv "$temp_file" "packages/$name"
                fi
              else
                echo "✗ Failed to download $name"
                rm -f "$temp_file"
              fi
            fi
          done
          echo ""
        }

        # Determine which repositories and releases to process
        if [ "$MODE" = "targeted" ]; then
          echo "=== Targeted Update Mode ==="
          # Determine release tag based on channel
          if [ "$CHANNEL" = "unstable" ]; then
            # For unstable channel, download from latest pre-release
            RELEASE_TAG="prerelease"
          else
            # For stable channel, download from latest stable release
            RELEASE_TAG="latest"
          fi

          download_from_repo "$TARGET_REPO" "$RELEASE_TAG"
        else
          echo "=== Full Rebuild Mode ==="
          echo "Downloading all packages and routing based on metadata..."

          # Download stable and unstable packages separately
          for channel in stable unstable; do
            if [ "$channel" = "unstable" ]; then
              RELEASE_TAG="prerelease"
            else
              RELEASE_TAG="latest"
            fi

            echo ""
            echo "--- Downloading $channel packages (release: $RELEASE_TAG) ---"

            # Clean packages directory
            rm -rf packages/*
            mkdir -p packages

            # Download packages for all repositories
            # Note: source scripts again here because the pipe creates a subshell
            # where the previously sourced variables are not available
            echo "${{ steps.discover.outputs.repos }}" | while IFS= read -r repo; do
              if [ -n "$repo" ]; then
                # Re-source in subshell for access to SUPPORTED_DISTROS and functions
                source scripts/suffix-parsing-functions.sh || { echo "❌ Failed to load suffix parsing functions"; exit 1; }
                source scripts/routing-functions.sh || { echo "❌ Failed to load routing functions"; exit 1; }
                download_from_repo "$repo" "$RELEASE_TAG"
              fi
            done

            # Route downloaded packages based on their metadata
            # This handles distro expansion and component routing
            if ls packages/*.deb 1> /dev/null 2>&1; then
              pkg_count=$(ls packages/*.deb | wc -l)
              echo "Routing $pkg_count packages ($channel channel) to appropriate distributions..."
              routing_failed=0

              for pkg in packages/*.deb; do
                pkg_name=$(basename "$pkg")
                meta_file="${pkg}.meta"

                # Clear metadata variables from previous iteration to prevent variable pollution
                unset distro component package version architecture original_filename

                # Read distro and component from metadata for logging
                if [ -f "$meta_file" ]; then
                  source "$meta_file" 2>/dev/null || {
                    echo "❌ Failed to read metadata for $pkg_name"
                    routing_failed=$((routing_failed + 1))
                    continue
                  }

                  # Log routing decision
                  if [ "$distro" = "any" ]; then
                    echo "  → $pkg_name (distro=any, component=$component)"
                    # Expand to all supported distributions
                    targets_list=""
                    for d in "${SUPPORTED_DISTROS[@]}"; do
                      targets_list="$targets_list ${d}-${channel}/$component"
                    done
                    echo "      Routes to:$targets_list"
                    if [ "$component" = "hatlabs" ]; then
                      echo "      + Legacy: ${channel}/main"
                    fi
                  else
                    echo "  → $pkg_name (distro=$distro, component=$component)"
                    echo "      Routes to: ${distro}-${channel}/$component"
                  fi
                fi

                # Perform actual routing
                if ! route_package "$pkg" "$channel"; then
                  echo "❌ Failed to route $pkg_name"
                  routing_failed=$((routing_failed + 1))
                fi
              done

              routed_count=$((pkg_count - routing_failed))

              if [ $routing_failed -eq 0 ]; then
                echo "✓ Successfully routed all $pkg_count $channel packages"
              else
                echo "❌ Failed to route $routing_failed/$pkg_count packages"
                exit 1
              fi
            else
              echo "ℹ No packages downloaded for $channel"
            fi
          done

          # Clean up packages directory after full rebuild
          rm -rf packages/*
        fi

        echo "=== Full rebuild completed ==="
    - name: Build APT repository structure
      run: |
        MODE="${{ steps.payload.outputs.mode }}"
        TARGET_DIST="${{ steps.payload.outputs.distribution }}"
        COMPONENT="${{ steps.payload.outputs.component }}"
        CHANNEL="${{ steps.payload.outputs.channel }}"

        # Source helper functions
        source scripts/suffix-parsing-functions.sh
        source scripts/routing-functions.sh

        # Route packages based on metadata (targeted mode only)
        # In full rebuild mode, packages are already routed in the Download step
        if [ "$MODE" = "targeted" ]; then
          if ls packages/*.deb 1> /dev/null 2>&1; then
            echo "=== Routing packages via metadata (Targeted mode) ==="
            routing_failed=0
            for pkg in packages/*.deb; do
              echo "Routing: $(basename "$pkg")"
              if ! route_package "$pkg" "$CHANNEL"; then
                echo "❌ Failed to route $(basename "$pkg")"
                routing_failed=$((routing_failed + 1))
              fi
            done
            pkg_count=$(ls packages/*.deb | wc -l)
            routed_count=$((pkg_count - routing_failed))

            if [ $routing_failed -eq 0 ]; then
              echo "✓ Successfully routed $pkg_count packages"
            else
              echo "❌ Failed to route $routing_failed/$pkg_count packages"
              exit 1
            fi
          else
            echo "ℹ No packages to route"
          fi
        else
          echo "=== Full Rebuild Mode: Packages already routed in Download step ==="
        fi

        cd apt-repo

        # Function to build distribution metadata for a specific component
        build_component() {
          local dist=$1
          local component=$2

          echo "=== Building distribution: $dist/$component ==="

          local dist_path="dists/$dist"
          local comp_path="$dist_path/$component"
          local pool_path="pool/$dist/$component"

          # Check if pool directory exists
          if [ ! -d "$pool_path" ]; then
            echo "ℹ Pool directory pool/$dist/$component does not exist - skipping"
            return 0
          fi

          # Check if pool has any .deb packages
          if ! ls "$pool_path"/*.deb 1>/dev/null 2>&1; then
            echo "ℹ No .deb packages in pool/$dist/$component - skipping"
            return 0
          fi

          # Ensure directories exist
          mkdir -p "$comp_path/binary-arm64"
          mkdir -p "$comp_path/binary-armhf"
          mkdir -p "$comp_path/binary-all"

          # Generate Packages files for each architecture
          echo "Generating Packages files..."

          # ARM64 packages - scan only this component's pool
          dpkg-scanpackages -a arm64 "$pool_path" /dev/null > "$comp_path/binary-arm64/Packages" 2>/dev/null || touch "$comp_path/binary-arm64/Packages"
          gzip -kf "$comp_path/binary-arm64/Packages"

          # ARMHF packages - scan only this component's pool
          dpkg-scanpackages -a armhf "$pool_path" /dev/null > "$comp_path/binary-armhf/Packages" 2>/dev/null || touch "$comp_path/binary-armhf/Packages"
          gzip -kf "$comp_path/binary-armhf/Packages"

          # Architecture-independent packages - scan only this component's pool
          dpkg-scanpackages -a all "$pool_path" /dev/null > "$comp_path/binary-all/Packages" 2>/dev/null || touch "$comp_path/binary-all/Packages"
          gzip -kf "$comp_path/binary-all/Packages"

          echo "✓ Built $dist/$component"
        }

        # Function to build Release file for a distribution
        build_release() {
          local dist=$1

          echo "=== Generating Release file for $dist ==="

          local dist_path="dists/$dist"

          # Find components that have been built (have Packages files)
          # Only include known components (main, hatlabs) to prevent including temporary directories
          local components=""
          for comp in main hatlabs; do
            if [ -f "$dist_path/$comp/binary-arm64/Packages" ] || [ -f "$dist_path/$comp/binary-armhf/Packages" ] || [ -f "$dist_path/$comp/binary-all/Packages" ]; then
              components="$components $comp"
            fi
          done
          components=$(echo "$components" | xargs)

          # Default to main component if no packages found (ensures distribution appears in index)
          if [ -z "$components" ]; then
            echo "ℹ️  No packages in $dist, creating empty main component"
            components="main"
            # Ensure empty Packages files exist so the distribution is valid
            mkdir -p "$dist_path/main/binary-arm64"
            mkdir -p "$dist_path/main/binary-armhf"
            mkdir -p "$dist_path/main/binary-all"
            touch "$dist_path/main/binary-arm64/Packages"
            touch "$dist_path/main/binary-armhf/Packages"
            touch "$dist_path/main/binary-all/Packages"
            gzip -kf "$dist_path/main/binary-arm64/Packages"
            gzip -kf "$dist_path/main/binary-armhf/Packages"
            gzip -kf "$dist_path/main/binary-all/Packages"
          fi

          # Determine suite and description based on distribution pattern
          if [[ "$dist" == "stable" ]]; then
            SUITE="stable"
            CODENAME="stable"
            DESC="Hat Labs product packages (stable)"
          elif [[ "$dist" == "unstable" ]]; then
            SUITE="unstable"
            CODENAME="unstable"
            DESC="Hat Labs product packages (unstable - rolling)"
          elif [[ "$dist" =~ ^([a-z0-9]+)-(stable|unstable)$ ]]; then
            # Extract codename and stability from pattern like "bookworm-stable"
            CODENAME="${BASH_REMATCH[1]}"
            STABILITY="${BASH_REMATCH[2]}"
            SUITE="$dist"
            # Capitalize first letter of codename for description
            CODENAME_DISPLAY="$(echo ${CODENAME:0:1} | tr '[:lower:]' '[:upper:]')${CODENAME:1}"
            if [[ "$STABILITY" == "stable" ]]; then
              DESC="Halos packages for Debian $CODENAME_DISPLAY (stable)"
            else
              DESC="Halos packages for Debian $CODENAME_DISPLAY (unstable - rolling)"
            fi
          else
            SUITE="$dist"
            CODENAME="$dist"
            DESC="Hat Labs APT Repository - $dist"
          fi

          cd "$dist_path"

          cat > Release << EOF
        Origin: Hat Labs
        Label: Hat Labs APT Repository
        Suite: $SUITE
        Codename: $CODENAME
        Version: 1.0
        Architectures: arm64 armhf all
        Components: $components
        Description: $DESC
        Date: $(date -Ru)
        EOF

          # Add package checksums
          apt-ftparchive release . >> Release

          # Sign the Release file
          echo "Signing Release file..."
          gpg --batch --yes --detach-sign --armor -u $GPG_KEY_ID -o Release.gpg Release
          gpg --batch --yes --clear-sign -u $GPG_KEY_ID -o InRelease Release

          cd ../..
          echo "✓ Generated Release file for $dist"
        }

        # Determine which distributions to build
        if [ "$MODE" = "targeted" ]; then
          echo "=== Targeted Mode: Updating $TARGET_DIST only ==="
          build_component "$TARGET_DIST" "$COMPONENT"
          build_release "$TARGET_DIST"
        else
          echo "=== Full Rebuild Mode ==="
          echo "Building metadata for all distributions"

          # In full rebuild mode:
          # - Packages were routed by metadata in the Download step
          # - Each distribution has both main and hatlabs components
          # - Now build metadata for all components in all distributions

          for dist in ${{ steps.payload.outputs.all_distributions }}; do
            # Build main component if it has packages
            build_component "$dist" "main"
            # Build hatlabs component if it has packages
            build_component "$dist" "hatlabs"
            # Build Release file for this distribution (includes all components)
            build_release "$dist"
          done
        fi

        echo ""
        echo "=== Repository structure ==="
        find dists -name "Packages" -o -name "Release" | sort

    - name: Export public GPG key
      run: |
        cd apt-repo
        # Export the public key for users to download
        gpg --export --armor $GPG_KEY_ID > hat-labs-apt-key.asc

        # Also create a keyring file
        gpg --export $GPG_KEY_ID > hat-labs-apt-key.gpg

        # Get the fingerprint for the index page
        FINGERPRINT=$(gpg --fingerprint $GPG_KEY_ID | grep -A1 "pub " | tail -n1 | tr -d ' ')
        echo "GPG_FINGERPRINT=$FINGERPRINT" >> $GITHUB_ENV
        echo "Key fingerprint: $FINGERPRINT"

    - name: Install test dependencies
      run: |
        pip3 install pytest

    - name: Run index generation tests
      run: |
        cd scripts
        pytest test_generate_index.py -v

    - name: Generate repository index pages
      run: |
        set -e
        # Use Python script to generate multi-distribution index pages
        # Generates main index.html + individual pages for each distribution
        python3 scripts/generate_index.py \
          apt-repo \
          --gpg-fingerprint "$GPG_FINGERPRINT"

    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v4
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./apt-repo
        cname: apt.hatlabs.fi

    - name: Report status
      run: |
        echo "=== APT Repository Update Complete ==="
        echo "Repository deployed to: https://apt.hatlabs.fi"
        echo ""
        echo "Distribution Summary:"

        for dist in ${{ steps.payload.outputs.all_distributions }}; do
          dist_has_packages=false
          for component in main hatlabs; do
            pkgfile="apt-repo/dists/$dist/$component/binary-arm64/Packages"
            if [ -f "$pkgfile" ]; then
              count=$(grep -c '^Package:' "$pkgfile" 2>/dev/null || echo "0")
              echo "  $dist/$component: $count packages"
              dist_has_packages=true
            fi
          done
          if [ "$dist_has_packages" = false ]; then
            echo "  $dist: (not built this run)"
          fi
        done
